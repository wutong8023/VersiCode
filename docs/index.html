<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><head>
  <meta charset="utf-8">
  <meta name="description" content="VersiCode: A Benchmarking Dataset for Version-controllable Code Generation">
  <meta name="keywords" content="code generation, language models, llm">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VersiCode: Towards Version-controllable Code Generation</title>

  <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer="" src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
        .center-container {
            text-align: center;
        }
  </style>
  <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.1.2/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VersiCode: Towards Version-controllable Code Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=u1Qp8lUAAAAJ&view_op=list_works&sortby=pubdate">Tongtong Wu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=UneIZo8AAAAJ">Weigang Wu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=wqPJcxcAAAAJ">Xingyu Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=N1UUDi0AAAAJ">Kang Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=NJHR1ukAAAAJ">Suyu Ma</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Bo Jiang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=hrogvxoAAAAJ">Ping Yang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=0vCxuH4AAAAJ">Zhenchang Xing</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=wufXO1kAAAAJ">Yuan-Fang Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=Perjx5EAAAAJ">Gholamreza Haffari</a><sup>1</sup>,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Monash University, Australia;</span>
            <span class="author-block"><sup>2</sup>Nanjing University of Posts and Telecommunications, China;</span>
            <span class="author-block"><sup>3</sup>ByteDance Ltd., China;</span>
            <span class="author-block"><sup>4</sup>CSIRO's Data61, Australia;</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.07411" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://github.com/wutong8023/VersiCode" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Code Link. -->
              
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/AstoneNg/VersiCode" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-images fa-w-18" aria-hidden="true" focusable="false" data-prefix="far" data-icon="images" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M480 416v16c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V176c0-26.51 21.49-48 48-48h16v48H54a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6v-10h48zm42-336H150a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6V86a6 6 0 0 0-6-6zm6-48c26.51 0 48 21.49 48 48v256c0 26.51-21.49 48-48 48H144c-26.51 0-48-21.49-48-48V80c0-26.51 21.49-48 48-48h384zM264 144c0 22.091-17.909 40-40 40s-40-17.909-40-40 17.909-40 40-40 40 17.909 40 40zm-72 96l39.515-39.515c4.686-4.686 12.284-4.686 16.971 0L288 240l103.515-103.515c4.686-4.686 12.284-4.686 16.971 0L480 208v80H192v-48z"></path></svg><!-- <i class="far fa-images"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Data</span>
                </a>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/AstoneNg/VersiCode" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon-[logos--hugging-face-icon]">
                    </span>
                    <span>HF Space</span>
                  </a>
                </span>
            </span></div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">VersiCode</span> is the first comprehensive dataset designed to assess the ability of large language models to generate verifiable code for specific library versions.
      </h2>
      <img src="static/images/introduction(1).png" alt="Introduce tasks.">
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Significant research and development efforts have gone into enhancing large language models' performance on code-related tasks due to their practical importance. 
Models' performance on these tasks is typically measured on public benchmark datasets. Current datasets, however, are oblivious to the notion of \emph{versions}, an essential concept in professional software development. 
In this paper, we introduce VersiCode, the first comprehensive dataset designed to assess the ability of large language models to generate verifiable code for specific library versions. VersiCode encompasses 301 libraries across more than 2,000 versions spanning 9 years. We design two dedicated evaluation tasks: version-specific code completion (VSCC) and version-aware code editing (VACE). Comprehensive experiments are conducted to benchmark the performance of LLMs, revealing the challenging nature of these tasks and VersiCode, that even state-of-the-art LLMs struggle to generate version-correct code. 
This dataset, together with the proposed tasks, sheds light on LLMs' capabilities and limitations in handling version-specific code generation, and opens up an important new area of research for further investigation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div></section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">VersiCode: A Benchmark for Version-controllable Code Generation</h2>
        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Overall Model Performance</h3> -->
        <div class="content has-text-justified">
          <p>
          <span style="color: red"><b>VersiCode</b></span> is a large-scale code generation benchmark dataset focusing on evolving library dependencies. We propose two tasks to simulate real-world applications: version-specific code completion and version-aware code editing, incorporating version information into code generation constraints.
          </p>
          The <span style="color: red"><b>Data statistics of VersiCode</b></span> is as follows.<br>
          <style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
          <table class="tg"><thead>
  <tr>
    <th class="tg-0lax"></th>
    <th class="tg-baqh" colspan="5">Python</th>
    <th class="tg-baqh">Java</th>
    <th class="tg-baqh">C\#</th>
    <th class="tg-baqh">JavaScript</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-0lax"># Data Source</td>
    <td class="tg-baqh" colspan="5">StackOverflow; Library Source Code; Downstream Application</td>
    <td class="tg-baqh">StackOverflow</td>
    <td class="tg-baqh">StackOverflow</td>
    <td class="tg-baqh">StackOverflow</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Num. of Libraries</td>
    <td class="tg-baqh" colspan="5">301</td>
    <td class="tg-baqh">19</td>
    <td class="tg-baqh">16</td>
    <td class="tg-baqh">33</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Num. of Versions</td>
    <td class="tg-baqh" colspan="5">2,208</td>
    <td class="tg-baqh">25</td>
    <td class="tg-baqh">16</td>
    <td class="tg-baqh">60</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Size of Meta Data</td>
    <td class="tg-baqh" colspan="5">11,269</td>
    <td class="tg-baqh">29</td>
    <td class="tg-baqh">16</td>
    <td class="tg-baqh">62</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Task Type</td>
    <td class="tg-baqh" colspan="3">Completion</td>
    <td class="tg-baqh">Editing (old to new)</td>
    <td class="tg-baqh">Editing (new to old)</td>
    <td class="tg-baqh">Completion</td>
    <td class="tg-baqh">Completion</td>
    <td class="tg-baqh">Completion</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Granularity</td>
    <td class="tg-baqh">Token</td>
    <td class="tg-baqh">Line</td>
    <td class="tg-baqh">Block</td>
    <td class="tg-baqh">Block</td>
    <td class="tg-baqh">Block</td>
    <td class="tg-baqh">Block</td>
    <td class="tg-baqh">Block</td>
    <td class="tg-baqh">Block</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Avg. Input Token</td>
    <td class="tg-baqh">1,233</td>
    <td class="tg-baqh">1,212</td>
    <td class="tg-baqh">44</td>
    <td class="tg-baqh">115</td>
    <td class="tg-baqh">116</td>
    <td class="tg-baqh">47</td>
    <td class="tg-baqh">51</td>
    <td class="tg-baqh">56</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Avg. Output Token</td>
    <td class="tg-baqh">1</td>
    <td class="tg-baqh">9</td>
    <td class="tg-baqh">77</td>
    <td class="tg-baqh">70</td>
    <td class="tg-baqh">69</td>
    <td class="tg-baqh">220</td>
    <td class="tg-baqh">148</td>
    <td class="tg-baqh">131</td>
  </tr>
  <tr>
    <td class="tg-0lax"># Num. of Instances</td>
    <td class="tg-baqh">13,533</td>
    <td class="tg-baqh">13,531</td>
    <td class="tg-baqh">1,618</td>
    <td class="tg-baqh">49,346</td>
    <td class="tg-baqh">49,346</td>
    <td class="tg-baqh">32</td>
    <td class="tg-baqh">21</td>
    <td class="tg-baqh">82</td>
  </tr>
</tbody></table>
        </div>
        <div class="columns is-vcentered interpolation-panel">
        </div>
        <br>
        <div class="content has-text-justified">
          <h3 class="title is-4">Dataset Curation and Collection</h3>
          <p>
          As shown in Figure 2, we first collected permissively licensed Python repositories from GitHub, ranked by popularity (stars). For each library, we gathered data from three sources. 
          </p>
          <p>
            1. <span style="color: red"><b>Library Source Code: </b></span>Collected all available versions from <b>GitHub</b> and verified with <b>PyPI</b> to ensure they are officially released and pip-installable. Extracted official usage examples for each API from the docstrings.
          </p>
          <p>
            2. <span style="color: red"><b>Downstream Application Code: </b></span>Collected source code from <b>top-tier research papers</b> over the past 10 years, given Python's popularity in scientific programming. These applications are lightweight, diverse in topics, and have release timelines tied to publishing venues, implicitly covering evolving libraries. 
          </p>
          <p>
            3. <span style="color: red"><b>StackOverflow: </b></span>Using library names as queries, collected <b>FAQ data</b> from StackOverflow, providing real user queries and diverse user answers.
          </p>
          <img src="static/images/dataset curation and collection.png" alt="dataset curation and collection">
        </div>
        <div class="content has-text-justified">
          <h3 class="title is-4">Task Design for Version-controllable Code Generation</h3>
          <p>
          As shown in Figure 3, we define each meta-instance \( m_i = [l_i, v_i, d_i, c_i] \in M \), where \( l \), \( v \), \( d \), and \( c \) represent the library name, version, functionality description, and code snippet, respectively. We then
design the following two version-controllable code generation tasks.
          </p>
          <ul>
            <li><span style="color: red"><b>Version-Specific Code Completion (VSCC): </b></span>Given a meta-instance \( x = [l_i, v_i, d_i, c'_i] \), where \( c'_i \) is the code snippet \( c_i \) with selective masking, replacing the library- and
version-sensitive contents with a special token. Depending on the length of the masked contents,
the special token is defined as “[token-mask]”, “[line-mask]”, or “[block-mask]”, reflecting code
completion on different granularity levels. The output y is the masked content, typically containing
function names or variables</li>
            <li><span style="color: red"><b>Version-Aware Code Editing (VACE): </b></span>Given a pair of meta-instances \( (m_i, m_j \mid l_i == l_j , d_i == d_j , v_i \neq v_j) \), the input \( x = [l_i, v_i, d_i, c_i, v_j] \), and the output \( y = c_j \). Note that version editing may
require refactoring of the code structure, making it difficult to format as detailed as in token-level
or line-level completion. Additionally, depending on the numerical relationship between \( v_i \) and \( v_j \), various scenarios arise, such as editing from an old version to a new version, or vice versa.</li>
          </ul>
          <div class="center-container">
            <img src="static/images/tasks design.png" alt="tasks design">
          </div>
        </div>
        <div class="content has-text-justified">
          <h3 class="title is-4">Comparison between VersiCode and other datasets</h3>
          <h4 class="title is-8">Code editing datasets</h4>
          <p>
          </p><ul>
            <li><span style = "color: red"><b>VersiCode</b></span> stands out as the largest annotated dataset specifically tailored for version adaptation.</li>
            
          </ul>
          <div class="center-container">
            <img src="static/images/coompare code editing datasets.png" alt="coompare code editing datasets">
          </div>
          <p></p>
          <h4 class="title is-8">Code completion datasets</h4>
          <ul>
            <li><span style = "color: red"><b>VersiCode</b></span> stands out in annotated data size, marking it as the inaugural dataset tailored for version-specific generation.</li>
            
          </ul>
          <div class="center-container">
            <img src="static/images/compare code completion datasets.png" alt="compare code completion datasets">
          </div>
        </div>
      </div></div></div></section>
      <section class="section">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Results and Analysis</h2>
              <div class="columns is-vcentered interpolation-panel">
              </div>
              <br>
              <div class="content has-text-justified">
                <h3 class="title is-4">Main Results</h3>
                <p>
                <span style = "color: red"><b>VersiCode</b></span> is challenging.
                </p>
                <div class="center-container">
                  <img src="static/images/main results.png" alt="main results">
                </div>
              </div>
              <div class="content has-text-justified">
                <h3 class="title is-4">Analysis</h3>
                <div class="center-container">
                  <img src="static/images/analysis datasets.png" alt="analysis datasets">
                </div>
                <h4 class="title is-8">(A) Even token-level code completion is challenging</h4>
                <p>We present the pass@1 results of token-level
code completion for LLMs on VersiCode, sorted by release time (see Figure 4-a1, highlighted in
green). When compared to the Pass@1 results on HumanEval (in blue) and MBPP (in orange),
all models perform significantly worse on VersiCode (in green). This result indicates the difficulty
in disambiguating and recalling version-specific library usage. It is worth noting that the larger
and latest models, such as GPT-4o (M13) and LLaMA3-70B (M12), achieve significantly better
performance than the other models (See Appendix D.1 for the error analysis of GPT-4o.). However,
the performance gap with HumanEval and MBPP is still large, with at least 15 points. Thus, for
the simplest token-level completion task, state-of-the-art LLMs struggle to achieve satisfactory
performance.</p>

                <h4 class="title is-8">(B) Differences in LLM performance across different data sources</h4> 
                <p>We present the Pass@1 results,
categorized by data sources, of token-level code completion for LLMs on VersiCode in Figure 4-a2.
Comparing these three data sources, most models perform much better on Stack Overflow than on the
other two, especially the source code from downstream applications. This result may be due to the
high diversity in downstream applications, which requires a strong ability to tackle them. It may also suggest that Stack Overflow is highly represented in the pre-training data of LLMs, hence a greater
chance of data leakage. Similar to Figure 4-a1, the outliers are still GPT-4o (M13) and LLaMA3-70B
(M12), which excel in dealing with downstream applications increasing the likelihood of models
memorizing specific content. Please refer to our <a href="https://arxiv.org/abs/2406.07411">paper</a> for full numeric results.</p>
                <h4 class="title is-8">(C) Challenges in casual intermediate library versions</h4>
                <p>We present the token-level Pass@1 results
categorized by lifespan features: addition (in blue), deprecation (in orange), and general (referring
to intermediate versions; in green) for the token-level code completion task (see Figure 4-b). Most
models perform well in the cases of addition and deprecation due to newly added or deprecated
APIs, as these versions are likely emphasized in documentation or by the community. However,
most models struggle with reasoning and adapting to intermediate versions. When viewed alongside
Figure 4-a2, it is evident that models such as LLaMA3-70B perform better in downstream applications
and are also good at intermediate versions, benefiting from the diversity of use cases.</p>
                <h4 class="title is-8">(D) Reduced context increases error risk in code generation</h4>
                <p>Based on the token-level code completion performance of each model, we selected the top models for further analysis. We present
the multi-granularity comparison in Table 3. When comparing the performance between line-level
and block-level code completion, we can observe that smaller models tend to fail more frequently
at generating correct code in block-level completion, due to less code context and the requirement
to generate more content, which aligns with our intuition. Note that the results shown here have
been filtered by grammar verification, a post-generation validation step that only counts code that
successfully compiles in Python. If we remove grammar verification, the overall performance of
block-level completion in Table 11 (<a href="https://arxiv.org/abs/2406.07411">Appendix E.3</a>) is comparable to line-level completion in Table 3.
This suggests that while the models can predict code-style content, they cannot guarantee correct
programming grammar.</p>
                <h4 class="title is-8">(E) The context code in another version is still helpful, but its benefits are limited</h4>
                <p>The comparison
between block-level code completion and block-level code editing is shown in Table 3. There is a
significant improvement across most models, except for LLaMA3-70B and GPT4-o. When provided
with code in another version as context (i.e. in the code editing task), these models can generate
correct code with a much higher success rate. However, a bottleneck is evident in LLaMA3-70B and
GPT4-o, where the code context hinders their performance compared to code completion.</p>
                <h4 class="title is-8">(F) Major version matters in version-aware code editing</h4>
                <p>As shown in Table 3, “old to new” editing
and “new to old” demonstrate similar performance among models. As shown in Figure 4, we
categorize editing instances according to their source and target versions, distinguishing between
major and minor versions. It’s evident that when the major version serves as the source, the model’s
editing performance is inferior compared to other scenarios.</p>
                <h4 class="title is-8">(G) The programming knowledge of LLMs, particularly regarding version-specific information,
is surprisingly outdated</h4>
                <p>In Figure 5 we present the Pass@1 performance for token-level code
completion, grouped by year, covering 2015-2023. Additionally, we show the histogram of data
distribution for each year. To ensure precise timestamps and minimize noise, we only used instances
collected from library source code. As shown in Figure 5-a we can observe a general trend: the
later the time, the worse the models’ performance. This is counter-intuitive compared to temporal
knowledge question answering [48], where performance initially increases before declining. We
further filtered for “deprecation” (Figure 5-b) and “addition” (Figure 5-c) to identify version-sensitive
cases. While the sparsity of data decreases confidence in results, in both cases, we can observe a consistent decreasing trend over time. This suggests that LLMs have outdated programming
knowledge, highlighting the need for rapid adaptation to newer libraries and APIs.</p>
                <div class="center-container">
                  <img src="static/images/time analysis.png" alt="time analysis">
                </div>
              </div>
            </div></div></div></section>
      

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{versicode,
  author={Tongtong Wu, Weigang Wu, Xingyu Wang, Kang Xu, Suyu Ma, Bo Jiang, Ping Yang, Zhenchang Xing, Yuan-Fang Li, Gholamreza Haffari},
  title        = {VersiCode: Towards Version-controllable Code Generation},
  journal      = {CoRR},
  volume       = {abs/2406.07411},
  year         = {2024},
  url          = {https://arxiv.org/abs/2406.07411},
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="">
        <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
      </a>
      <a class="icon-link" href="" disabled="">
        <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>



</body></html>
